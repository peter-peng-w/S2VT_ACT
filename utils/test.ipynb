{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('../data/MSR-VTT/train_val_annotation/train_val_example.json') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "print(len(data['videos']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'category': 9, 'url': 'https://www.youtube.com/watch?v=9lZi22qLlEo', 'video_id': 'video0', 'start time': 137.72, 'end time': 149.44, 'split': 'train', 'id': 0}\n",
      "{'category': 9, 'url': 'https://www.youtube.com/watch?v=QA7KVQq9vKA', 'video_id': 'video2', 'start time': 31.17, 'end time': 41.24, 'split': 'train', 'id': 2}\n"
     ]
    }
   ],
   "source": [
    "for videos_info in data['videos']:\n",
    "    if videos_info['category'] == 9:\n",
    "        print(videos_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'videos': [], 'sentences': []}\n"
     ]
    }
   ],
   "source": [
    "train_data = {'videos':[], 'sentences':[]}\n",
    "print(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'videos': [{'category': 9, 'url': 'https://www.youtube.com/watch?v=9lZi22qLlEo', 'video_id': 'video0', 'start time': 137.72, 'end time': 149.44, 'split': 'train', 'id': 0}, {'category': 9, 'url': 'https://www.youtube.com/watch?v=QA7KVQq9vKA', 'video_id': 'video2', 'start time': 31.17, 'end time': 41.24, 'split': 'train', 'id': 2}], 'sentences': []}\n"
     ]
    }
   ],
   "source": [
    "for videos_info in data['videos']:\n",
    "    if videos_info['category'] == 9:\n",
    "        train_data['videos'].append(videos_info)\n",
    "print(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sentences_info in data['sentences']:\n",
    "    if sentences_info['video_id'] == 'video2960':\n",
    "        train_data['sentences'].append(sentences_info)\n",
    "with open('data.json', 'w') as fp:\n",
    "    json.dump(train_data, fp, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load all the data info for train and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('../data/MSR-VTT/data.json') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract a subset of the whole dataset\n",
    "Based on the category information, we are interested in the following categories:\n",
    "* people, category id: 1\n",
    "* gaming, category id: 2\n",
    "* sports/actions, category id: 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "200000\n"
     ]
    }
   ],
   "source": [
    "print(len(data['videos']))\n",
    "print(len(data['sentences']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnt_train: {'people': 157, 'gaming': 308, 'sports': 713}\n",
      "cnt_valid: {'people': 16, 'gaming': 24, 'sports': 71}\n"
     ]
    }
   ],
   "source": [
    "cnt_train = {'people':0, 'gaming':0, 'sports':0}\n",
    "cnt_valid = {'people':0, 'gaming':0, 'sports':0}\n",
    "for video_info in data['videos']:\n",
    "    if video_info['category'] == 1:\n",
    "        if video_info['split'] == 'train':\n",
    "            cnt_train['people'] += 1\n",
    "        elif video_info['split'] == 'validate':\n",
    "            cnt_valid['people'] += 1\n",
    "        else:\n",
    "            raise ValueError\n",
    "    elif video_info['category'] == 2:\n",
    "        if video_info['split'] == 'train':\n",
    "            cnt_train['gaming'] += 1\n",
    "        elif video_info['split'] == 'validate':\n",
    "            cnt_valid['gaming'] += 1\n",
    "        else:\n",
    "            raise ValueError\n",
    "    elif video_info['category'] == 3:\n",
    "        if video_info['split'] == 'train':\n",
    "            cnt_train['sports'] += 1\n",
    "        elif video_info['split'] == 'validate':\n",
    "            cnt_valid['sports'] += 1\n",
    "        else:\n",
    "            raise ValueError\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "print(\"cnt_train: {}\".format(cnt_train))\n",
    "print(\"cnt_valid: {}\".format(cnt_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_id2category = {}\n",
    "for video_info in data['videos']:\n",
    "    video_id2category[video_info['video_id']] = video_info['category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A1': 'drink', 'A2': 'eat', 'A3': 'brush', 'A4': 'brush', 'A5': 'drop', 'A6': 'pick', 'A7': 'throw', 'A8': 'sit', 'A9': 'stand', 'A10': 'clap', 'A11': 'read', 'A12': 'write', 'A13': 'tear', 'A14': 'jacket', 'A15': 'jacket', 'A16': 'shoe', 'A17': 'shoe', 'A18': 'glasses', 'A19': 'glasses', 'A20': 'hat', 'A21': 'hat', 'A22': 'cheer', 'A23': 'wave', 'A24': 'kick', 'A25': 'reach', 'A26': 'hop', 'A27': 'jump', 'A28': 'phone', 'A29': 'play', 'A30': 'type', 'A31': 'point', 'A32': 'selfie', 'A33': 'time', 'A34': 'rub', 'A35': 'nod', 'A36': 'shake', 'A37': 'wipe', 'A38': 'salute', 'A39': 'palm', 'A40': 'cross', 'A41': 'cough', 'A42': 'stagger', 'A43': 'fall', 'A44': 'headache', 'A45': 'chest', 'A46': 'back', 'A47': 'neck', 'A48': 'vomit', 'A49': 'fan', 'A50': 'punch', 'A51': 'kick', 'A52': 'push', 'A53': 'pat', 'A54': 'finger', 'A55': 'hug', 'A56': 'give', 'A57': 'pocket', 'A58': 'shake', 'A59': 'walk', 'A60': 'walk', 'A61': 'slap'}\n"
     ]
    }
   ],
   "source": [
    "action_set = {}\n",
    "with open('../data/actions_short.txt', 'rt') as f:\n",
    "    for line in f:\n",
    "        if len(line) > 2:\n",
    "            line_data = line.strip().split(': ')\n",
    "            action_set[line_data[0]] = line_data[1]\n",
    "f.close()\n",
    "print(action_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A1': 0, 'A2': 0, 'A3': 0, 'A4': 0, 'A5': 0, 'A6': 0, 'A7': 0, 'A8': 0, 'A9': 0, 'A10': 0, 'A11': 0, 'A12': 0, 'A13': 0, 'A14': 0, 'A15': 0, 'A16': 0, 'A17': 0, 'A18': 0, 'A19': 0, 'A20': 0, 'A21': 0, 'A22': 0, 'A23': 0, 'A24': 0, 'A25': 0, 'A26': 0, 'A27': 0, 'A28': 0, 'A29': 0, 'A30': 0, 'A31': 0, 'A32': 0, 'A33': 0, 'A34': 0, 'A35': 0, 'A36': 0, 'A37': 0, 'A38': 0, 'A39': 0, 'A40': 0, 'A41': 0, 'A42': 0, 'A43': 0, 'A44': 0, 'A45': 0, 'A46': 0, 'A47': 0, 'A48': 0, 'A49': 0, 'A50': 0, 'A51': 0, 'A52': 0, 'A53': 0, 'A54': 0, 'A55': 0, 'A56': 0, 'A57': 0, 'A58': 0, 'A59': 0, 'A60': 0, 'A61': 0}\n",
      "{'A1': 0, 'A2': 0, 'A3': 0, 'A4': 0, 'A5': 0, 'A6': 0, 'A7': 0, 'A8': 0, 'A9': 0, 'A10': 0, 'A11': 0, 'A12': 0, 'A13': 0, 'A14': 0, 'A15': 0, 'A16': 0, 'A17': 0, 'A18': 0, 'A19': 0, 'A20': 0, 'A21': 0, 'A22': 0, 'A23': 0, 'A24': 0, 'A25': 0, 'A26': 0, 'A27': 0, 'A28': 0, 'A29': 0, 'A30': 0, 'A31': 0, 'A32': 0, 'A33': 0, 'A34': 0, 'A35': 0, 'A36': 0, 'A37': 0, 'A38': 0, 'A39': 0, 'A40': 0, 'A41': 0, 'A42': 0, 'A43': 0, 'A44': 0, 'A45': 0, 'A46': 0, 'A47': 0, 'A48': 0, 'A49': 0, 'A50': 0, 'A51': 0, 'A52': 0, 'A53': 0, 'A54': 0, 'A55': 0, 'A56': 0, 'A57': 0, 'A58': 0, 'A59': 0, 'A60': 0, 'A61': 0}\n",
      "{'A1': 0, 'A2': 0, 'A3': 0, 'A4': 0, 'A5': 0, 'A6': 0, 'A7': 0, 'A8': 0, 'A9': 0, 'A10': 0, 'A11': 0, 'A12': 0, 'A13': 0, 'A14': 0, 'A15': 0, 'A16': 0, 'A17': 0, 'A18': 0, 'A19': 0, 'A20': 0, 'A21': 0, 'A22': 0, 'A23': 0, 'A24': 0, 'A25': 0, 'A26': 0, 'A27': 0, 'A28': 0, 'A29': 0, 'A30': 0, 'A31': 0, 'A32': 0, 'A33': 0, 'A34': 0, 'A35': 0, 'A36': 0, 'A37': 0, 'A38': 0, 'A39': 0, 'A40': 0, 'A41': 0, 'A42': 0, 'A43': 0, 'A44': 0, 'A45': 0, 'A46': 0, 'A47': 0, 'A48': 0, 'A49': 0, 'A50': 0, 'A51': 0, 'A52': 0, 'A53': 0, 'A54': 0, 'A55': 0, 'A56': 0, 'A57': 0, 'A58': 0, 'A59': 0, 'A60': 0, 'A61': 0}\n",
      "{'A1': 0, 'A2': 0, 'A3': 0, 'A4': 0, 'A5': 0, 'A6': 0, 'A7': 0, 'A8': 0, 'A9': 0, 'A10': 0, 'A11': 0, 'A12': 0, 'A13': 0, 'A14': 0, 'A15': 0, 'A16': 0, 'A17': 0, 'A18': 0, 'A19': 0, 'A20': 0, 'A21': 0, 'A22': 0, 'A23': 0, 'A24': 0, 'A25': 0, 'A26': 0, 'A27': 0, 'A28': 0, 'A29': 0, 'A30': 0, 'A31': 0, 'A32': 0, 'A33': 0, 'A34': 0, 'A35': 0, 'A36': 0, 'A37': 0, 'A38': 0, 'A39': 0, 'A40': 0, 'A41': 0, 'A42': 0, 'A43': 0, 'A44': 0, 'A45': 0, 'A46': 0, 'A47': 0, 'A48': 0, 'A49': 0, 'A50': 0, 'A51': 0, 'A52': 0, 'A53': 0, 'A54': 0, 'A55': 0, 'A56': 0, 'A57': 0, 'A58': 0, 'A59': 0, 'A60': 0, 'A61': 0}\n"
     ]
    }
   ],
   "source": [
    "cnt_actions = {}\n",
    "cnt_category_1_actions = {}\n",
    "cnt_category_2_actions = {}\n",
    "cnt_category_3_actions = {}\n",
    "for key in action_set.keys():\n",
    "    cnt_actions[key] = 0\n",
    "    cnt_category_1_actions[key] = 0\n",
    "    cnt_category_2_actions[key] = 0\n",
    "    cnt_category_3_actions[key] = 0\n",
    "print(cnt_actions)\n",
    "print(cnt_category_1_actions)\n",
    "print(cnt_category_2_actions)\n",
    "print(cnt_category_3_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actions count:\n",
      "{'A1': 2493, 'A2': 19019, 'A3': 1166, 'A4': 1166, 'A5': 759, 'A6': 1160, 'A7': 2288, 'A8': 17512, 'A9': 11240, 'A10': 764, 'A11': 4298, 'A12': 264, 'A13': 142, 'A14': 2198, 'A15': 2198, 'A16': 650, 'A17': 650, 'A18': 3334, 'A19': 3334, 'A20': 14729, 'A21': 14729, 'A22': 1690, 'A23': 1388, 'A24': 1125, 'A25': 439, 'A26': 3442, 'A27': 5062, 'A28': 7570, 'A29': 74960, 'A30': 1742, 'A31': 2391, 'A32': 851, 'A33': 2586, 'A34': 1596, 'A35': 102, 'A36': 392, 'A37': 138, 'A38': 7, 'A39': 197, 'A40': 2451, 'A41': 36, 'A42': 8, 'A43': 3317, 'A44': 4, 'A45': 513, 'A46': 9105, 'A47': 733, 'A48': 44, 'A49': 1639, 'A50': 405, 'A51': 1125, 'A52': 1051, 'A53': 2550, 'A54': 896, 'A55': 1943, 'A56': 3497, 'A57': 99, 'A58': 392, 'A59': 16746, 'A60': 16746, 'A61': 123}\n",
      "category match count:\n",
      "{0: 5287, 1: 2269, 2: 5556, 3: 12718, 4: 3491, 5: 2395, 6: 2439, 7: 8335, 8: 2743, 9: 5324, 10: 3800, 11: 3160, 12: 3271, 13: 6588, 14: 3693, 15: 1480, 16: 4690, 17: 1964, 18: 6030, 19: 1781}\n",
      "positive videos number: 9284\n",
      "positive sentences number: 64482\n"
     ]
    }
   ],
   "source": [
    "positive_videos = set()\n",
    "positive_sentences = set()\n",
    "cnt_category = {0:0,1:0,2:0,3:0,4:0,5:0,6:0,7:0,8:0,9:0,10:0,11:0,12:0,13:0,14:0,15:0,16:0,17:0,18:0,19:0}\n",
    "for sentence_info in data['sentences']:\n",
    "    for key in action_set.keys():\n",
    "        if action_set[key] in sentence_info['caption']:\n",
    "            cnt_actions[key] += 1\n",
    "            positive_videos.add(sentence_info['video_id'])\n",
    "            positive_sentences.add(sentence_info['sen_id'])\n",
    "            cnt_category[video_id2category[sentence_info['video_id']]] += 1\n",
    "\n",
    "print('actions count:')\n",
    "print(cnt_actions)\n",
    "print('category match count:')\n",
    "print(cnt_category)\n",
    "print('positive videos number: {}'.format(len(positive_videos)))\n",
    "print('positive sentences number: {}'.format(len(positive_sentences)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6515\n"
     ]
    }
   ],
   "source": [
    "print(len(positive_videos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A1': 35, 'A2': 391, 'A3': 8, 'A4': 8, 'A5': 22, 'A6': 40, 'A7': 241, 'A8': 369, 'A9': 319, 'A10': 53, 'A11': 137, 'A12': 1, 'A13': 1, 'A14': 31, 'A15': 31, 'A16': 17, 'A17': 17, 'A18': 54, 'A19': 54, 'A20': 395, 'A21': 395, 'A22': 160, 'A23': 133, 'A24': 95, 'A25': 17, 'A26': 110, 'A27': 358, 'A28': 240, 'A29': 8045, 'A30': 27, 'A31': 160, 'A32': 119, 'A33': 90, 'A34': 15, 'A35': 1, 'A36': 15, 'A37': 1, 'A38': 0, 'A39': 5, 'A40': 142, 'A41': 0, 'A42': 0, 'A43': 198, 'A44': 0, 'A45': 18, 'A46': 377, 'A47': 6, 'A48': 0, 'A49': 0, 'A50': 56, 'A51': 95, 'A52': 28, 'A53': 114, 'A54': 10, 'A55': 102, 'A56': 92, 'A57': 0, 'A58': 15, 'A59': 395, 'A60': 395, 'A61': 7}\n"
     ]
    }
   ],
   "source": [
    "cnt_category_123_actions = {}\n",
    "for key in action_set.keys():\n",
    "    cnt_category_123_actions[key] = cnt_category_1_actions[key] + cnt_category_2_actions[key] + cnt_category_3_actions[key]\n",
    "print(cnt_category_123_actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Lite subset of MSR-VTT10k for local testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Loading all the info...\n",
      "Finished selecting video info...\n",
      "Finished selecting caption info...\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "# Load the data\n",
    "with open('../data/MSR-VTT/train_val_annotation/train_val_videodatainfo.json') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "print('Finished Loading all the info...')\n",
    "\n",
    "data_lite = {'videos':[], 'sentences':[]}\n",
    "\n",
    "for videos_info in data['videos']:\n",
    "    if int(videos_info['id']) < 100:\n",
    "        if int(videos_info['id']) >= 80:\n",
    "            videos_info['split'] = \"test\"\n",
    "        elif int(videos_info['id']) >= 70:\n",
    "            videos_info['split'] = \"validate\"\n",
    "        data_lite['videos'].append(videos_info)\n",
    "\n",
    "print('Finished selecting video info...')\n",
    "\n",
    "for sentences_info in data['sentences']:\n",
    "    if int(sentences_info['video_id'].strip().split('video')[1]) < 100:\n",
    "        data_lite['sentences'].append(sentences_info)\n",
    "\n",
    "print('Finished selecting caption info...')\n",
    "\n",
    "with open('data_lite.json', 'w') as fp:\n",
    "    json.dump(data_lite, fp, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the Total set of MSR-VTT10k for online trainig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# Load the data\n",
    "with open('../data/MSR-VTT/Train_Val_annotation/train_val_videodatainfo.json') as f1:\n",
    "    data_train_val = json.load(f1)\n",
    "f1.close()\n",
    "\n",
    "with open('../data/MSR-VTT/Test_Annotation/test_videodatainfo.json') as f2:\n",
    "    data_test = json.load(f2)\n",
    "f2.close()\n",
    "\n",
    "print('Finished Loading all the info...')\n",
    "\n",
    "data_lite = {'videos':[], 'sentences':[]}\n",
    "\n",
    "for videos_info in data_train_val['videos']:\n",
    "    data_lite['videos'].append(videos_info)\n",
    "\n",
    "for videos_info in data_test['videos']:\n",
    "    data_lite['videos'].append(videos_info)\n",
    "\n",
    "print('Finished selecting video info...')\n",
    "\n",
    "for sentences_info in data_train_val['sentences']:\n",
    "    data_lite['sentences'].append(sentences_info)\n",
    "\n",
    "for sentences_info in data_test['sentences']:\n",
    "    data_lite['sentences'].append(sentences_info)\n",
    "\n",
    "print('Finished selecting caption info...')\n",
    "\n",
    "with open('data_lite.json', 'w') as fp:\n",
    "    json.dump(data_lite, fp, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the caption data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'captions': ['a man holds two dogs', 'a man introducing he two large dogs', 'a man is holding two dog s in his hand and talking about that', 'a man is sitting while he s hugging and petting two dogs', 'a man is talking to the camera while cuddling two dogs', 'a man is talking with 2 dogs on the camera', 'a man is vlogging saying he happy birthday', 'a man is with his dogs', 'a man sits with a dog and a bear cub', 'a man squatting with two dogs tells someone happy birthday', 'a man talking to the camera with two dogs next to him', 'a man talks and plays with his two dogs', 'a man with wo dogs is speaking to the camera', 'a person is with his pets', 'a person wishes someone a happy birthday while hugging dogs', 'a woman sings while on the floor with her laptop then a man wishes people happy birthday', 'man introduces his two dogs', 'the man had several dogs', 'video with guy and two dogs', 'a man is sitting while he s hugging and petting two dogs'], 'final_captions': [['<SOS>', 'a', 'man', 'holds', 'two', 'dogs', '<EOS>'], ['<SOS>', 'a', 'man', 'introducing', 'he', 'two', 'large', 'dogs', '<EOS>'], ['<SOS>', 'a', 'man', 'is', 'holding', 'two', 'dog', 's', 'in', 'his', 'hand', 'and', 'talking', 'about', 'that', '<EOS>'], ['<SOS>', 'a', 'man', 'is', 'sitting', 'while', 'he', 's', 'hugging', 'and', 'petting', 'two', 'dogs', '<EOS>'], ['<SOS>', 'a', 'man', 'is', 'talking', 'to', 'the', 'camera', 'while', '<UNK>', 'two', 'dogs', '<EOS>'], ['<SOS>', 'a', 'man', 'is', 'talking', 'with', '2', 'dogs', 'on', 'the', 'camera', '<EOS>'], ['<SOS>', 'a', 'man', 'is', '<UNK>', 'saying', 'he', 'happy', 'birthday', '<EOS>'], ['<SOS>', 'a', 'man', 'is', 'with', 'his', 'dogs', '<EOS>'], ['<SOS>', 'a', 'man', 'sits', 'with', 'a', 'dog', 'and', 'a', '<UNK>', '<UNK>', '<EOS>'], ['<SOS>', 'a', 'man', '<UNK>', 'with', 'two', 'dogs', 'tells', 'someone', 'happy', 'birthday', '<EOS>'], ['<SOS>', 'a', 'man', 'talking', 'to', 'the', 'camera', 'with', 'two', 'dogs', 'next', 'to', 'him', '<EOS>'], ['<SOS>', 'a', 'man', 'talks', 'and', 'plays', 'with', 'his', 'two', 'dogs', '<EOS>'], ['<SOS>', 'a', 'man', 'with', '<UNK>', 'dogs', 'is', 'speaking', 'to', 'the', 'camera', '<EOS>'], ['<SOS>', 'a', 'person', 'is', 'with', 'his', '<UNK>', '<EOS>'], ['<SOS>', 'a', 'person', 'wishes', 'someone', 'a', 'happy', 'birthday', 'while', 'hugging', 'dogs', '<EOS>'], ['<SOS>', 'a', 'woman', 'sings', 'while', 'on', 'the', 'floor', 'with', 'her', 'laptop', 'then', 'a', 'man', 'wishes', 'people', 'happy', 'birthday', '<EOS>'], ['<SOS>', 'man', 'introduces', 'his', 'two', 'dogs', '<EOS>'], ['<SOS>', 'the', 'man', 'had', 'several', 'dogs', '<EOS>'], ['<SOS>', 'video', 'with', 'guy', 'and', 'two', 'dogs', '<EOS>'], ['<SOS>', 'a', 'man', 'is', 'sitting', 'while', 'he', 's', 'hugging', 'and', 'petting', 'two', 'dogs', '<EOS>']]}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "captions = json.load(open('../data/caption.json'))\n",
    "print(captions['video10'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['in a kitchen a woman adds different ingredients into the pot and stirs it', 'a woman puts prawns and seasonings into a large pot on a stove', 'in the kitchen a woman makes a dish by adding ingredients mixing and allowing to boil on flame', 'a woman adding ingredients to a pot on the stove and stirring', 'instructions on how to cook a dish of prawns or crayfish are given on screen while the chef prepares the dish', 'a woman is in the kitchen making a recipe in a large pot with many ingredients', 'a woman adds some packets of spices and spoonfuls of tomato sauce to a pot then stirs it and covers the pot', 'a person add ingredients to a pot in a counter than stirs it', 'a person puts items in a pot on the stove in the kitchen', 'a woman cooking food with a metal pan on top of a stove', 'a woman adds different ingredients into a a pot on the stove', 'a woman in a kitchen is cooking a stew in a large pan on her stove', 'a women in a multi-color outfit is cooking a stew type dish in a silver pot', 'a woman adds ingredients to a pot that is simmering on a stove', 'a woman is preparing a seafood stew recipe on a stove demonstrating each step herself while at the same time the easy to read directions', 'in a kitchen a lady preferred crayfish with mixing of curry powder', 'a  woman and a bowl  spoon mixing dish inside kitchen to prepare to serve to eat displaying on screen', 'cooking the dried smoked prawn in a vessel having boiled water and the lied closed', 'a lady is making dried prawns curry and she added tomato puree and salt in it', 'a woman in a colorful scarf is showing how to make a stew']\n",
      "[['<SOS>', 'in', 'a', 'kitchen', 'a', 'woman', 'adds', 'different', 'ingredients', 'into', 'the', 'pot', 'and', 'stirs', 'it', '<EOS>'], ['<SOS>', 'a', 'woman', 'puts', 'prawns', 'and', '<UNK>', 'into', 'a', 'large', 'pot', 'on', 'a', 'stove', '<EOS>'], ['<SOS>', 'in', 'the', 'kitchen', 'a', 'woman', 'makes', 'a', 'dish', 'by', 'adding', 'ingredients', 'mixing', 'and', '<UNK>', 'to', '<UNK>', 'on', '<UNK>', '<EOS>'], ['<SOS>', 'a', 'woman', 'adding', 'ingredients', 'to', 'a', 'pot', 'on', 'the', 'stove', 'and', '<UNK>', '<EOS>'], ['<SOS>', 'instructions', 'on', 'how', 'to', 'cook', 'a', 'dish', 'of', 'prawns', 'or', 'crayfish', 'are', 'given', 'on', 'screen', 'while', 'the', '<UNK>', 'prepares', 'the', 'dish', '<EOS>'], ['<SOS>', 'a', 'woman', 'is', 'in', 'the', 'kitchen', 'making', 'a', 'recipe', 'in', 'a', 'large', 'pot', 'with', 'many', 'ingredients', '<EOS>'], ['<SOS>', 'a', 'woman', 'adds', 'some', '<UNK>', 'of', '<UNK>', 'and', '<UNK>', 'of', 'tomato', '<UNK>', 'to', 'a', 'pot', 'then', 'stirs', 'it', 'and', '<UNK>', 'the', 'pot', '<EOS>'], ['<SOS>', 'a', 'person', '<UNK>', 'ingredients', 'to', 'a', 'pot', 'in', 'a', 'counter', 'than', 'stirs', 'it', '<EOS>'], ['<SOS>', 'a', 'person', 'puts', 'items', 'in', 'a', 'pot', 'on', 'the', 'stove', 'in', 'the', 'kitchen', '<EOS>'], ['<SOS>', 'a', 'woman', 'cooking', 'food', 'with', 'a', 'metal', 'pan', 'on', 'top', 'of', 'a', 'stove', '<EOS>'], ['<SOS>', 'a', 'woman', 'adds', 'different', 'ingredients', 'into', 'a', 'a', 'pot', 'on', 'the', 'stove', '<EOS>'], ['<SOS>', 'a', 'woman', 'in', 'a', 'kitchen', 'is', 'cooking', 'a', 'stew', 'in', 'a', 'large', 'pan', 'on', 'her', 'stove', '<EOS>'], ['<SOS>', 'a', 'women', 'in', 'a', '<UNK>', 'outfit', 'is', 'cooking', 'a', 'stew', 'type', 'dish', 'in', 'a', '<UNK>', 'pot', '<EOS>'], ['<SOS>', 'a', 'woman', 'adds', 'ingredients', 'to', 'a', 'pot', 'that', 'is', '<UNK>', 'on', 'a', 'stove', '<EOS>'], ['<SOS>', 'a', 'woman', 'is', 'preparing', 'a', 'seafood', 'stew', 'recipe', 'on', 'a', 'stove', 'demonstrating', 'each', 'step', 'herself', 'while', 'at', 'the', 'same', 'time', 'the', '<UNK>', 'to', 'read', 'directions', '<EOS>'], ['<SOS>', 'in', 'a', 'kitchen', 'a', 'lady', '<UNK>', 'crayfish', 'with', 'mixing', 'of', 'curry', 'powder', '<EOS>'], ['<SOS>', 'a', 'woman', 'and', 'a', 'bowl', 'spoon', 'mixing', 'dish', 'inside', 'kitchen', 'to', 'prepare', 'to', 'serve', 'to', 'eat', 'displaying', 'on', 'screen', '<EOS>'], ['<SOS>', 'cooking', 'the', 'dried', '<UNK>', '<UNK>', 'in', 'a', 'vessel', 'having', 'boiled', 'water', 'and', 'the', '<UNK>', '<UNK>', '<EOS>'], ['<SOS>', 'a', 'lady', 'is', 'making', 'dried', 'prawns', 'curry', 'and', 'she', 'added', 'tomato', '<UNK>', 'and', 'salt', 'in', 'it', '<EOS>'], ['<SOS>', 'a', 'woman', 'in', 'a', 'colorful', '<UNK>', 'is', 'showing', 'how', 'to', 'make', 'a', 'stew', '<EOS>']]\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "print(captions['video1']['captions'])\n",
    "print(captions['video1']['final_captions'])\n",
    "print(len(captions['video1']['final_captions']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A1': 'drink', 'A2': 'eat', 'A3': 'brush', 'A4': 'brush', 'A5': 'drop', 'A6': 'pick', 'A7': 'throw', 'A8': 'sit', 'A9': 'stand', 'A10': 'clap', 'A11': 'read', 'A12': 'write', 'A13': 'tear', 'A14': 'jacket', 'A15': 'jacket', 'A16': 'shoe', 'A17': 'shoe', 'A18': 'glasses', 'A19': 'glasses', 'A20': 'hat', 'A21': 'hat', 'A22': 'cheer', 'A23': 'wave', 'A24': 'kick', 'A25': 'reach', 'A26': 'hop', 'A27': 'jump', 'A28': 'phone', 'A29': 'play', 'A30': 'type', 'A31': 'point', 'A32': 'selfie', 'A33': 'time', 'A34': 'rub', 'A35': 'nod', 'A36': 'shake', 'A37': 'wipe', 'A38': 'salute', 'A39': 'palm', 'A40': 'cross', 'A41': 'cough', 'A42': 'stagger', 'A43': 'fall', 'A44': 'headache', 'A45': 'chest', 'A46': 'back', 'A47': 'neck', 'A48': 'vomit', 'A49': 'fan', 'A50': 'punch', 'A51': 'kick', 'A52': 'push', 'A53': 'pat', 'A54': 'finger', 'A55': 'hug', 'A56': 'give', 'A57': 'pocket', 'A58': 'shake', 'A59': 'walk', 'A60': 'walk', 'A61': 'slap'}\n"
     ]
    }
   ],
   "source": [
    "print(action_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'hold' in captions['video10']['captions'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A1': 0, 'A2': 0, 'A3': 0, 'A4': 0, 'A5': 0, 'A6': 0, 'A7': 0, 'A8': 3, 'A9': 0, 'A10': 0, 'A11': 0, 'A12': 0, 'A13': 0, 'A14': 0, 'A15': 0, 'A16': 0, 'A17': 0, 'A18': 0, 'A19': 0, 'A20': 1, 'A21': 1, 'A22': 0, 'A23': 0, 'A24': 0, 'A25': 0, 'A26': 0, 'A27': 0, 'A28': 0, 'A29': 1, 'A30': 0, 'A31': 0, 'A32': 0, 'A33': 0, 'A34': 0, 'A35': 0, 'A36': 0, 'A37': 0, 'A38': 0, 'A39': 0, 'A40': 0, 'A41': 0, 'A42': 0, 'A43': 0, 'A44': 0, 'A45': 0, 'A46': 0, 'A47': 0, 'A48': 0, 'A49': 0, 'A50': 0, 'A51': 0, 'A52': 0, 'A53': 0, 'A54': 0, 'A55': 3, 'A56': 0, 'A57': 0, 'A58': 0, 'A59': 0, 'A60': 0, 'A61': 0}\n"
     ]
    }
   ],
   "source": [
    "idx = 10\n",
    "cnt_actions_in_cap = {}\n",
    "\n",
    "for key in action_set.keys():\n",
    "    cnt_actions_in_cap[key] = 0\n",
    "\n",
    "for cap in captions['video%i'%(idx)]['captions']:\n",
    "    for key in action_set.keys():\n",
    "        if action_set[key] in cap:\n",
    "            cnt_actions_in_cap[key] += 1\n",
    "\n",
    "print(cnt_actions_in_cap)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "action_freq = list(cnt_actions_in_cap.values())\n",
    "print(action_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[54]\n",
      "hug\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "if sum(action_freq) > 0:\n",
    "    act_select_idx = np.random.choice(61, 1, p=np.array(action_freq)/sum(action_freq))\n",
    "    print(act_select_idx)\n",
    "    print(list(action_set.values())[act_select_idx[0]])\n",
    "else:\n",
    "    print('<PAD>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}